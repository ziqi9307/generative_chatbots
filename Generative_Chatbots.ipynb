{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative_Chatbots.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmGsafDoes9v1CuH3kcnr7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziqi9307/generative_chatbots/blob/main/Generative_Chatbots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Chatbots Using Reccurent Neural Nets"
      ],
      "metadata": {
        "id": "NhF5TCuaqFa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DLeY44DFwTDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "061elnAArNA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**<br>\n",
        "Open twitter_prep.py and preprocessing.py in a code editor or IDE.\n",
        "In twitter_prep.py, change data_path to the file path of [your-topic].txt. If it‚Äôs in the same directory as twitter_prep.py, then all you need is the file name. <br>\n",
        "\n",
        "At the bottom of twitter_prep.py, print out all the response pairs from the data. Run the file to see the format they are in. Then comment the print statement out. <br>\n",
        "\n",
        "In preprocessing.py, adjust the number of lines of training data you want to work with. We‚Äôre giving you a default of 15, but depending on how much you want to tax your computer, you can go up to -1 (the last line of the file).\n",
        "Run preprocessing.py and make sure everything works, error-free."
      ],
      "metadata": {
        "id": "on2a34bArhaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import twitter_prep\n",
        "twitter_prep.pairs"
      ],
      "metadata": {
        "id": "eVBYTL1Irpcr",
        "outputId": "1f1288c9-6b56-490a-e78e-8512a227f754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('im changing my cats name to tofu',\n",
              "  'imagine naming ur cat gooby instead of tofu to begin w..'),\n",
              " (\"i wish she'd learn to use cutlery, she's making a right mess!\",\n",
              "  'omg... just like my cat!'),\n",
              " ('can you find the cat in each photo?üòÇ', 'what cat?'),\n",
              " ('glad we agree', \"i don't like the way that cat is looking at me\"),\n",
              " ('it shen , he meows and purrs lot !', 'good cat'),\n",
              " ('i guess someone had a busy day',\n",
              "  'cats are very busy creatures, always on important cat business'),\n",
              " ('no, his name is . . . mr. tiggles üòÖ',\n",
              "  'that mr mayhem commercial where he acts like a cat knocking that stuff off the counter makes me laugh.'),\n",
              " ('‚îÄ were always there when it came to cats. brushing her knuckles across its cheek.',\n",
              "  'isn‚Äôt he lovely? [magnus smiled softly at the sight of the cat getting familiar, purring'),\n",
              " ('casual photo of me and max getting ready to judge your replies to this tweet..',\n",
              "  'i love your cat ryan!'),\n",
              " ('the cats in cats as presidential nominees: a thread (1/?)',\n",
              "  'biden is this cat:'),\n",
              " ('she nods a bit before padding over to him. food and water sound amazing right now. and somewhere warm to nap.',\n",
              "  'tenya poured in some fresh water, and some cat food, then slid the bowls over to the cat.'),\n",
              " ('omg i love lil tuxedo babies thats what rae isüò≠üíòüíò',\n",
              "  'peaches (our 20 year old geriatric) had a tuxedo brother named gizmo'),\n",
              " ('update: he jumped for real this morning. thankfully, he landed on a cardboard box and seems to have walked away',\n",
              "  'stunt cat. :/'),\n",
              " ('larry.... üòªüòªüòª they should install a buzzer for you to be able to paw for entry',\n",
              "  'one of the panels should be refitted as a cat flap'),\n",
              " ('i think i may have found what tim was talking about',\n",
              "  'that cat looks thrilled about the whole thing'),\n",
              " ('i am eating hummus on rye. hummus. on. rye. and he still wants my sandwich. #tongueouttuesday',\n",
              "  'that is the face of a cat who never, ever gets fed. üòÇ'),\n",
              " ('might as well put it to good use!',\n",
              "  'absolutely. laptop on bed, cat on my feet, very cozy. üòÖ'),\n",
              " ('hey folks! pepita is awake &amp; i am picking her up later this afternoon! i accidentally stepped on her tail last night',\n",
              "  'i‚Äôm so glad she‚Äôs okay! but also literally everyone who has a cat has stepped on it.'),\n",
              " (\"appreciate your pets everyone. they won't be there forever. let's see your pets of past and present\",\n",
              "  'this is milo celebrating my arrival back after xmas doing the you haven‚Äôt been with another cat check'),\n",
              " ('(he got distracted too. there are so many! and all of them are so cute! arthur possibly is in heaven',\n",
              "  \"what would you like to order? (he's stroking that cat and it's purring, settling on his lap. feels nice‚Ä¶\"),\n",
              " ('my boss and i have been working on this one case for an hour and 7 mins üåö',\n",
              "  'my cat acted a fool the whole time sis was literally trying to open the fridge üò≠'),\n",
              " ('help her‚òùÔ∏è', 'my my cat mossad agent demand it!'),\n",
              " ('absolutely. laptop on bed, cat on my feet, very cozy. üòÖ',\n",
              "  'same minus the cat üòÇ bc i didn‚Äôt leave my apt during this episode bc they told me i didn‚Äôt need to'),\n",
              " ('having a really rough time today friends. please send pictures of cats. big hugs xox',\n",
              "  'here‚Äôs a cat that meowed at my front door so i let it in'),\n",
              " (\"meet the fat, bald cat that's becoming a body positivity icon\",\n",
              "  'this isnt good, that cat is most likely suffering because it cant just be a normal cat.'),\n",
              " (\"they'll be left feline sad üòø\", 'the bbc is a cat-astrophe')]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Js2ym5YQsWax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pqh4EXLZscA2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "K2NlojSVtgXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open training_model.py.\n",
        "Change the values for the following: <br><br>\n",
        "**batch_size:** You can choose to adjust this or not at this point. This determines how many response pairs are used at a time for training. <br>\n",
        "**epochs:** This should be a larger number so that the seq2seq model has many chances to improve. Bear in mind that a larger number of epochs will also take your computer a lot longer to process. If you don‚Äôt have the ability to leave your computer running awhile for this project, then choose a number that is less than 500. <br><br>\n",
        "<hr><br>\n",
        "\n",
        "Run the code to generate your model. In the terminal, you should see a summary of the model printed out. Meanwhile, you‚Äôll also see a new file in the directory called training_model.h5. This is where your seq2seq training model is saved so that it‚Äôs quicker for you to run your code when you instantiate the chatbot. <br>\n",
        "Note that you may get the following error when attempting to run your program on a regular computer that uses CPU processing:\n",
        "\n",
        "OMP: Error #15: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized.\n",
        "OMP: Hint: This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n",
        "Abort trap: 6"
      ],
      "metadata": {
        "id": "riUZFlrXtlBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocessing import num_encoder_tokens, num_decoder_tokens, decoder_target_data, encoder_input_data, decoder_input_data, decoder_target_data, max_encoder_seq_length, max_decoder_seq_length\n",
        "\n",
        "from tensorflow import keras\n",
        "# Add Dense to the imported layers\n",
        "from keras.layers import Input, LSTM, Dense, Masking\n",
        "from keras.models import Model\n",
        "import os\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# Choose dimensionality\n",
        "dimensionality = 256\n",
        "\n",
        "# Choose the batch size\n",
        "# and number of epochs:\n",
        "batch_size = 10\n",
        "epochs = 50\n",
        "\n",
        "# Encoder training setup\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "\n",
        "# Decoder training setup:\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Building the training model:\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model:\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "\n",
        "# print(\"Training the model:\\n\")\n",
        "# Train the model:\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "\n",
        "training_model.save('training_model.h5')"
      ],
      "metadata": {
        "id": "8vLgl91JsfAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}